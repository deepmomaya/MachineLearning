{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_732\\3506535508.py:3: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  tsearch = re.search('([A-Za-z]+)\\.', name)\n"
     ]
    }
   ],
   "source": [
    "def extract_titles(name):\n",
    "    # Extracts titles from names.\n",
    "    tsearch = re.search('([A-Za-z]+)\\.', name)\n",
    "    if tsearch:\n",
    "        return tsearch.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def process_data(data):\n",
    "    # Feature engineering\n",
    "    data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "    data['Has_Cabin'] = data[\"Cabin\"].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "    data['Fare'] = data['Fare'].fillna(train['Fare'].median())\n",
    "    data.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "    data['IsAlone'].fillna(0, inplace=True)  # Filling missing values\n",
    "    data['Embarked'] = data['Embarked'].fillna('S')\n",
    "\n",
    "    # Filling missing values in 'Age' column with random values within one standard deviation from the mean\n",
    "    standard = data['Age'].std()\n",
    "    average = data['Age'].mean()\n",
    "    nullage = data['Age'].isnull().sum()\n",
    "    nullagelist = np.random.randint(average - standard, average + standard, size=nullage)\n",
    "    data.loc[np.isnan(data['Age']), 'Age'] = nullagelist\n",
    "    data['Age'] = data['Age'].astype(int)\n",
    "\n",
    "    # Extracting titles from names\n",
    "    data['Title'] = data['Name'].apply(extract_titles)\n",
    "    data['Title'] = data['Title'].replace({'Mme': 'Mrs', 'Ms': 'Miss', 'Mlle': 'Miss'})\n",
    "\n",
    "    # Mapping categorical variables\n",
    "    data['Sex'] = data['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "    tmap = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4}\n",
    "    data['Title'] = data['Title'].map(tmap)\n",
    "    data['Title'] = data['Title'].fillna(0)\n",
    "    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n",
    "\n",
    "    # Binning numerical features\n",
    "    data['Fare'] = pd.cut(data['Fare'], bins=[0, 10, 20, 30, np.inf], labels=[0, 1, 2, 3])\n",
    "    data['Fare'] = data['Fare'].cat.codes\n",
    "    data['Age'] = pd.cut(data['Age'], bins=[0, 16, 32, 48, 64, np.inf], labels=[0, 1, 2, 3, 4])\n",
    "    data['Age'] = data['Age'].cat.codes\n",
    "\n",
    "    # Dropping unnecessary columns\n",
    "    drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Sex']\n",
    "    data.drop(drop_elements, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_732\\3506535508.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['IsAlone'].fillna(0, inplace=True)  # Filling missing values\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_732\\3506535508.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['IsAlone'].fillna(0, inplace=True)  # Filling missing values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Age  Parch  Fare  Embarked  FamilySize  Has_Cabin  \\\n",
       "0           0       3    1      0     0         0           2          0   \n",
       "1           1       1    2      0     3         1           2          1   \n",
       "2           1       3    1      0     0         0           1          0   \n",
       "3           1       1    2      0     3         0           2          1   \n",
       "4           0       3    2      0     0         0           1          0   \n",
       "..        ...     ...  ...    ...   ...       ...         ...        ...   \n",
       "886         0       2    1      0     1         0           1          0   \n",
       "887         1       1    1      0     2         0           1          1   \n",
       "888         0       3    1      2     2         0           4          0   \n",
       "889         1       1    1      0     2         1           1          1   \n",
       "890         0       3    1      0     0         2           1          0   \n",
       "\n",
       "     IsAlone  Title  \n",
       "0        0.0    1.0  \n",
       "1        0.0    3.0  \n",
       "2        1.0    4.0  \n",
       "3        0.0    3.0  \n",
       "4        1.0    1.0  \n",
       "..       ...    ...  \n",
       "886      1.0    0.0  \n",
       "887      1.0    4.0  \n",
       "888      0.0    4.0  \n",
       "889      1.0    1.0  \n",
       "890      1.0    1.0  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data(train)\n",
    "process_data(test)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, impurity='gini', max_depth=10, min_samples_split=4, min_samples_leaf=2):\n",
    "        \"\"\"\n",
    "        Initialize the DecisionTree model.\n",
    "\n",
    "        Parameters:\n",
    "            impurity (str): The impurity criterion to be used for splitting.\n",
    "            max_depth (int): The maximum depth of the decision tree.\n",
    "            min_samples_split (int): The minimum number of samples required to split an internal node.\n",
    "            min_samples_leaf (int): The minimum number of samples required to be at a leaf node.\n",
    "        \"\"\"\n",
    "        self.impurity = impurity\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        \n",
    "        # Define impurity criterion functions\n",
    "        self.criterion_functions = {\n",
    "            'gini': lambda y: 1 - np.sum((np.unique(y, return_counts=True)[1] / len(y)) ** 2),\n",
    "            'entropy': lambda y: -np.sum((np.unique(y, return_counts=True)[1] / len(y)) *\n",
    "                                          np.log2(np.unique(y, return_counts=True)[1] / len(y))),\n",
    "            'misclassification_rate': lambda y: 1 - np.max(np.unique(y, return_counts=True)[1] / len(y))\n",
    "        }\n",
    "        \n",
    "        # Select impurity measure based on user input or default to 'gini'\n",
    "        self.homogeneity_measure = self.criterion_functions.get(impurity, self.criterion_functions['gini'])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit the decision tree model to the training data.\n",
    "        # Convert input data to numpy arrays if they are DataFrame or Series\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        # Recursively split the data to construct the decision tree\n",
    "        self.tree = self.split(X, y, 0)\n",
    "\n",
    "    def split(self, X, y, depth):\n",
    "        # Recursively splits the data to create the decision tree.\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Check stopping conditions: minimum samples or maximum depth reached\n",
    "        if n_samples < self.min_samples_split or depth > self.max_depth:\n",
    "            # Create leaf node and assign the mean value of target variable\n",
    "            return {'leaf_value': np.round(np.mean(y))}\n",
    "        \n",
    "        # Initialize variables for best split\n",
    "        best_left_X, best_left_y, best_right_X, best_right_y = None, None, None, None\n",
    "        best_feature, best_threshold, best_impurity = None, None, np.inf\n",
    "        \n",
    "        # Iterate over features and their unique values to find best split\n",
    "        for feature in range(n_features):\n",
    "            unique_values = np.unique(X[:, feature])\n",
    "            for threshold in unique_values:\n",
    "                # Split data into left and right based on threshold\n",
    "                left_index = X[:, feature] <= threshold\n",
    "                right_index = ~left_index\n",
    "                left_y, right_y = y[left_index], y[right_index]\n",
    "                \n",
    "                # Calculate impurity for left and right splits\n",
    "                impurity = (len(left_y) / n_samples) * self.homogeneity_measure(left_y) + \\\n",
    "                           (len(right_y) / n_samples) * self.homogeneity_measure(right_y)\n",
    "                \n",
    "                # Update best split if impurity is minimized\n",
    "                if impurity < best_impurity:\n",
    "                    best_feature, best_threshold, best_impurity = feature, threshold, impurity\n",
    "                    best_left_X, best_left_y = X[left_index], y[left_index]\n",
    "                    best_right_X, best_right_y = X[right_index], y[right_index]\n",
    "        \n",
    "        # Check if a valid split was found\n",
    "        if best_feature is not None:\n",
    "            # Recursively split the left and right nodes\n",
    "            left_subtree = self.split(best_left_X, best_left_y, depth + 1)\n",
    "            right_subtree = self.split(best_right_X, best_right_y, depth + 1)\n",
    "            \n",
    "            # Construct tree node with split information and subtrees\n",
    "            return {'feature': best_feature,\n",
    "                    'threshold': best_threshold,\n",
    "                    'left': left_subtree,\n",
    "                    'right': right_subtree}\n",
    "        \n",
    "        # If no valid split was found, create leaf node with mean target value\n",
    "        return {'leaf_value': np.round(np.mean(y))}\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predicts the target values for the input samples.\n",
    "        X = pd.DataFrame(X)\n",
    "        \n",
    "        # Reset index to ensure correct iteration over rows\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Initialize array to store predictions\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        # Iterate over input samples and make predictions using the decision tree\n",
    "        for i in range(X.shape[0]):\n",
    "            y_pred[i] = self.predict_single(X.loc[i], self.tree)\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    def predict_single(self, x, node):\n",
    "        # Traverse the tree until a leaf node is reached\n",
    "        while 'leaf_value' not in node:\n",
    "            # Determine which subtree to follow based on the feature and threshold\n",
    "            if x[node['feature']] <= node['threshold']:\n",
    "                node = node['left']\n",
    "            else:\n",
    "                node = node['right']\n",
    "        \n",
    "        # Return the predicted target value at the leaf node\n",
    "        return node['leaf_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Python312\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Model : 79.10%\n",
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 891, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_732\\478174472.py:105: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if x[node['feature']] <= node['threshold']:\n"
     ]
    }
   ],
   "source": [
    "# Splitting data into features (X) and target variable (y)\n",
    "y = train['Survived']\n",
    "X = train.drop('Survived', axis=1)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initializing and fitting the Decision Tree model\n",
    "decisiontree = DecisionTree(max_depth=5)\n",
    "decisiontree.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "ypred = decisiontree.predict(X_test)\n",
    "\n",
    "# Calculating accuracy of the Decision Tree model\n",
    "dacc = accuracy_score(y_test, ypred)\n",
    "print(\"Accuracy of Decision Tree Model : {:.2f}%\".format(dacc * 100))\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, classifier, num_trees, min_features):\n",
    "        \"\"\"\n",
    "        Initialize the Random Forest classifier.\n",
    "\n",
    "        Parameters:\n",
    "            classifier (class): The base decision tree classifier class.\n",
    "            num_trees (int): Number of decision trees in the forest.\n",
    "            min_features (int): Minimum number of features to consider for each tree.\n",
    "        \"\"\"\n",
    "        self.classifier = classifier\n",
    "        self.num_trees = num_trees\n",
    "        self.min_features = min_features\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Fit the Random Forest model to the training data.\n",
    "        # Reset index for both features and target variable\n",
    "        X = X.reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "\n",
    "        # Build each decision tree in the forest\n",
    "        for i in range(self.num_trees):\n",
    "            # Randomly select subset of data with replacement\n",
    "            cnt = np.random.randint(1, X.shape[0] + 1)\n",
    "            sid = np.random.choice(X.index, cnt, replace=True)\n",
    "            X_b, y_b = X.loc[sid], y.loc[sid]\n",
    "\n",
    "            # Randomly select subset of features without replacement\n",
    "            feats = np.random.randint(self.min_features, X.shape[1] + 1)\n",
    "            fid = np.random.choice(X.columns, feats, replace=False)\n",
    "            X_b = X_b[fid]\n",
    "\n",
    "            # Initialize and fit the decision tree with the subset of data and features\n",
    "            tree = self.classifier(max_depth=10, min_samples_split=2, min_samples_leaf=2)\n",
    "            tree.fit(X_b, y_b)\n",
    "            \n",
    "            # Store the fitted tree along with the selected features\n",
    "            self.trees.append((tree, fid))\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the target variable for the input data.\n",
    "        # Make predictions using each decision tree in the forest\n",
    "        aa = []\n",
    "        for tree, fid in self.trees:\n",
    "            xx = X[fid]\n",
    "            aa.append(tree.predict(xx))\n",
    "        \n",
    "        # Combine predictions from all trees and return the most frequent prediction for each sample\n",
    "        aa = np.array(aa).astype(int)\n",
    "        return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest Model : 78.36%\n",
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initializing and fitting the Random Forest model\n",
    "randomforest = RandomForest(classifier=DecisionTreeClassifier, num_trees=100, min_features=4)\n",
    "randomforest.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "ypredr = randomforest.predict(X_test)\n",
    "\n",
    "# Calculating accuracy of the Random Forest model\n",
    "racc = accuracy_score(y_test, ypredr)\n",
    "print(\"Accuracy of Random Forest Model : {:.2f}%\".format(racc * 100))\n",
    "\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, weak_learner, num_learners, learning_rate):\n",
    "        \"\"\"\n",
    "        Initialize the AdaBoost classifier.\n",
    "\n",
    "        Parameters:\n",
    "            weak_learner (class): The base weak learner class.\n",
    "            num_learners (int): Number of weak learners (decision stumps) to train.\n",
    "            learning_rate (float): Learning rate to adjust the contribution of each weak learner.\n",
    "        \"\"\"\n",
    "        self.weak_learner = weak_learner\n",
    "        self.num_learners = num_learners\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Fit the AdaBoost model to the training data.\n",
    "        self.mm = []  # List to store trained weak learners\n",
    "        self.nn = []  # List to store weights of weak learners\n",
    "        cnt = X.shape[0]\n",
    "        yy = np.ones(cnt) / cnt  # Initialize sample weights\n",
    "\n",
    "        # Train each weak learner\n",
    "        for _ in range(self.num_learners):\n",
    "            ml = self.weak_learner()  # Initialize weak learner\n",
    "            ml.fit(X, y)  # Train weak learner\n",
    "            ypred = ml.predict(X)  # Make predictions using weak learner\n",
    "            grad = np.mean(np.abs(ypred - y) / 2 * yy) / np.mean(yy)  # Calculate error rate\n",
    "            if grad > 0.5:\n",
    "                break\n",
    "            dd = self.learning_rate * np.log((1 - grad) / grad)  # Calculate learner weight\n",
    "            self.mm.append(ml)  # Store weak learner\n",
    "            self.nn.append(dd)  # Store learner weight\n",
    "            yy *= np.exp(-dd * y * ypred)  # Update sample weights\n",
    "            yy /= np.sum(yy)  # Normalize sample weights\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # Predict the target variable for the input data.\n",
    "        n = X.shape[0]\n",
    "        ypred = np.zeros(n)\n",
    "        \n",
    "        # Make predictions using each weak learner and weight\n",
    "        for i in range(len(self.mm)):\n",
    "            m1 = self.mm[i]\n",
    "            m2 = self.nn[i]\n",
    "            ypred += m2 * m1.predict(X)  # Weighted sum of predictions\n",
    "        \n",
    "        # Apply sign function to get final predictions\n",
    "        return np.sign(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Boosting Model : 76.49%\n",
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Initializing and fitting the AdaBoost model\n",
    "ab = AdaBoost(weak_learner=DecisionTreeClassifier, num_learners=200, learning_rate=0.1)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "ypredb = ab.predict(X_test)\n",
    "\n",
    "# Calculating accuracy of the AdaBoost model\n",
    "bacc = accuracy_score(y_test, ypredb)\n",
    "print(\"Accuracy of Boosting Model : {:.2f}%\".format(bacc * 100))\n",
    "\n",
    "print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
